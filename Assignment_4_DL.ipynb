{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e091e62c",
   "metadata": {},
   "source": [
    "### 1. How would you describe TensorFlow in a short sentence? What are its main features? Can you name other popular Deep Learning libraries?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20624a33",
   "metadata": {},
   "source": [
    "### TensorFlow is an open-source deep learning library for building and training neural networks, known for its flexibility, scalability, and ecosystem of tools and extensions.\n",
    "\n",
    "Main features include:\n",
    "\n",
    "- Flexible architecture - uses high level API's like Keras for ease of use.\n",
    "- Efficient computation - uses GPU's TPU's\n",
    "- Auto differentiation - automatically computes gradients for backpropagation during training.\n",
    "- Extensive ecosystem - offers a rich ecosystem including TensorFlow Extended.\n",
    "\n",
    "\n",
    "1. PyTorch: A dynamic deep learning framework that is popular for research and known for its flexibility and ease of debugging.\n",
    "2. Keras: Although it's now part of TensorFlow, Keras remains a high-level API for building neural networks and is popular for its simplicity.\n",
    "3. Caffe: A deep learning framework that's widely used in computer vision applications.\n",
    "4. MXNet: A deep learning framework known for its scalability and support for both symbolic and imperative programming.\n",
    "5. Theano: An early deep learning library that pioneered GPU acceleration but is no longer actively developed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3b616e",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e755c08",
   "metadata": {},
   "source": [
    "### 2. Is TensorFlow a drop-in replacement for NumPy? What are the main differences between the two?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82939cd5",
   "metadata": {},
   "source": [
    "### TensorFlow is not a drop-in replacement for NumPy.\n",
    "\n",
    "### TensorFlow primarily uses a data structure called a \"tensor\" for representing multi-dimensional arrays, while NumPy uses \"numpy arrays.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db621d",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0320d4a",
   "metadata": {},
   "source": [
    "### 3. Do you get the same result with tf.range(10) and tf.constant(np.arange(10))?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a16560",
   "metadata": {},
   "source": [
    "Yes\n",
    "\n",
    "<tf.Tensor: shape=(10,), dtype=int32, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=int32)>\n",
    "\n",
    "<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfc662ca",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a5d7a",
   "metadata": {},
   "source": [
    "### 4. Can you name six other data structures available in TensorFlow, beyond regular tensors?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afacb841",
   "metadata": {},
   "source": [
    "SparseTensor: A SparseTensor is designed to efficiently represent sparse data, where many elements are zero. It consists of three components: indices, values, and dense_shape. This data structure is particularly useful for tasks like natural language processing (NLP), where text data is often sparse.\n",
    "\n",
    "RaggedTensor: RaggedTensor is a data structure for representing and handling ragged (non-uniform) data, such as sequences of varying lengths. It's commonly used in tasks like natural language processing and time series analysis.\n",
    "\n",
    "TensorArray: TensorArray is a dynamic-sized array that can be used to store and manipulate tensors of varying shapes and sizes within a TensorFlow computation graph. It's useful when dealing with dynamic or variable-length sequences in recurrent neural networks (RNNs) and other dynamic models.\n",
    "\n",
    "Queue-based Data Structures: TensorFlow provides queue-based data structures like tf.queue.FIFOQueue and tf.queue.PaddingFIFOQueue for managing data input pipelines in asynchronous and parallel processing. These are often used in data loading and preprocessing pipelines for training deep learning models.\n",
    "\n",
    "Variable: While not a traditional data structure, TensorFlow Variables are special tensors that are used to store and update model parameters (learnable weights) during training. Variables are a fundamental part of building and training neural networks in TensorFlow.\n",
    "\n",
    "Dataset: TensorFlow's Dataset API allows you to create efficient input pipelines for training deep learning models. While not a traditional data structure, a Dataset represents a sequence of data elements and provides methods for reading, transforming, and batching data for training or evaluation.\n",
    "\n",
    "These additional data structures in TensorFlow extend its capabilities beyond regular tensors and enable the handling of various data formats and requirements encountered in machine learning and deep learning tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98102bb1",
   "metadata": {},
   "source": [
    "---------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718213cc",
   "metadata": {},
   "source": [
    "### 5. A custom loss function can be defined by writing a function or by subclassing the keras.losses.Loss class. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c513c9",
   "metadata": {},
   "source": [
    "### Writing a custom loss function is suitable for straightforward loss calculations without any additional internal states or complex logic.\n",
    "### Good for cases where the loss computation doesn't require any trainable parameters or additional layers.\n",
    "\n",
    "### You use the subclass keras.Losses.Loss when your custom loss involves more complex logic, stateful computations, or if it requires trainable parameters. It allows you to define a class with a call method, which computes the loss. You can use __init__ to initialize any additional parameters or states needed for the loss computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2253452",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd074a2",
   "metadata": {},
   "source": [
    "### 6. Similarly, a custom metric can be defined in a function or a subclass of keras.metrics.Metric. When would you use each option?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cda25d",
   "metadata": {},
   "source": [
    "### Again using subclass keras.metrics.Metric is used when you want to do stateful computations, requires tracking values over batches or epochs, or needs additional parameters. It allows you to define a class with update_state, result, and optionally reset_states methods. You can use __init__ to initialize any additional parameters or states needed for the metric computation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d47fda",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c265ad62",
   "metadata": {},
   "source": [
    "### 7. When should you create a custom layer versus a custom model?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a4fc8",
   "metadata": {},
   "source": [
    "### Use a custom layer:\n",
    "1. to do low level operations that don't involve managing the entire model.\n",
    "2. To introduce trainable parameters wthin a specific operation.Use the add_weight method.\n",
    "3. Reuse a component that can easily integrate into different models.\n",
    "\n",
    "### Use a custom model:\n",
    "1. High level operation for multiple layers and interactions.\n",
    "2. Custom models allow you to define the forward pass, manage the loop and implement more complex architectures.\n",
    "\n",
    "### It is common to use custom layers within custom models. Custom layers can be incorporated into the architecture of a custom model to handle specific operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91aa0049",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2797000f",
   "metadata": {},
   "source": [
    "### 8. What are some use cases that require writing your own custom training loop?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71c550c",
   "metadata": {},
   "source": [
    "### writing your own custom training loop is when you want something specific. for e.g.\n",
    "1. novel research prototypes\n",
    "2. if you need a more sophisticated learning rate schedule that changes dynamically.\n",
    "3. complex loss computation.\n",
    "4. to avoid exploding gradient \n",
    "5. for evolving datasets\n",
    "6. to selectively freeze and update layers or parameters\n",
    "7. if you have custom evaluation metrics\n",
    "8. controlling regularization process\n",
    "9. to debug and profile\n",
    "10. to distribute training across multiple GPUs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06cf2f74",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7efb330e",
   "metadata": {},
   "source": [
    "### 9. Can custom Keras components contain arbitrary Python code, or must they be convertible to TF Functions?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35abf10d",
   "metadata": {},
   "source": [
    "### In TensorFlow 2.x, custom Keras components, including custom layers, custom models, and custom metrics, need to be convertible to TensorFlow Functions to take full advantage of TensorFlow's performance optimizations. TensorFlow Functions are part of TensorFlow's Autograph feature, which converts Python code into a graph representation for improved performance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d52d91e",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05bdb954",
   "metadata": {},
   "source": [
    "### 10. What are the main rules to respect if you want a function to be convertible to a TF Function?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc7e7648",
   "metadata": {},
   "source": [
    "1. Avoid Python side effects.\n",
    "2. operations inside the function should use Tensorflow operations rather than native Python operations.\n",
    "3. Avoid python data structures\n",
    "4. limit external dependencies\n",
    "5. be consistent with input signature\n",
    "6. error handling compatible with graph execution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488f2678",
   "metadata": {},
   "source": [
    "-----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be308a6c",
   "metadata": {},
   "source": [
    "### 11. When would you need to create a dynamic Keras model? How do you do that? Why not make all your models dynamic?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d73bf0e",
   "metadata": {},
   "source": [
    "### A dynamic Keras model is created when you want your input shape to be variable during runtime.\n",
    "\n",
    "for e.g. in natural language processing (NLP) tasks or other sequence-based models, sequences can have varying lengths. Dynamic models are beneficial when working with text or sequences of different lengths without the need for padding.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6a0c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense\n",
    "\n",
    "# Assume you have a vocabulary size and maximum sequence length\n",
    "vocab_size = 10000\n",
    "max_seq_length = None  # Set to None for variable sequence length\n",
    "\n",
    "# Define the input layer with variable sequence length\n",
    "input_layer = Input(shape=(max_seq_length,), dtype=tf.int32)\n",
    "\n",
    "# Embedding layer to convert integer indices to dense vectors\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=100)(input_layer)\n",
    "\n",
    "# LSTM layer to process variable-length sequences\n",
    "lstm_layer = LSTM(64)(embedding_layer)\n",
    "\n",
    "# Output layer for classification\n",
    "output_layer = Dense(1, activation='sigmoid')(lstm_layer)\n",
    "\n",
    "# Create the model\n",
    "dynamic_nlp_model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Display the model summary\n",
    "dynamic_nlp_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bcfa39",
   "metadata": {},
   "source": [
    "### You can't make all models dynamic as it is heavy on computation. They can have lower performance, can be heavy on memory usage and limited to deployment based on hardware and framework."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
